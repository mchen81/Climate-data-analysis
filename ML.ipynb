{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash\n",
    "from datetime import datetime\n",
    "\n",
    "def parseLine(line):\n",
    "    variables = line.split(\"\\t\")\n",
    "    try:\n",
    "        lat = float(variables[1])\n",
    "        lon = float(variables[2])\n",
    "        tem = float(variables[10])\n",
    "        humidity = float(variables[8])\n",
    "        wind_speed = float(variables[17])\n",
    "        cloud_cover = float(variables[12])   \n",
    "        \n",
    "        ts = int(variables[0][0: 10])\n",
    "        # if you encounter a \"year is out of range\" error the timestamp\n",
    "        # may be in milliseconds, try `ts /= 1000` in that case\n",
    "        yearMonth = datetime.utcfromtimestamp(ts).strftime('%Y-%m')\n",
    "        \n",
    "        gh = geohash.encode(lat, lon)\n",
    "        return (gh[0: 2] + '\\t' + yearMonth, tem, humidity, wind_speed, cloud_cover)\n",
    "    except:\n",
    "        return ('z?', 0, 0, 0, 0)\n",
    "    \n",
    "#text_file = spark.read.load('hdfs://orion11:21001/3hr_sample/sampled_2015/*', format='csv', sep='\\t', inferSchema=True, header=True)\n",
    "text_fileML = sc.textFile(\"hdfs://orion11:21001/3hr_sample/sampled_2018/*\")\n",
    "\n",
    "# (GeoHash, wind_energy_factor, cloud_cover)\n",
    "parsed_dataML8g = text_fileML \\\n",
    "    .map(lambda line: parseLine(line)) \\\n",
    "    .filter(lambda line: line[0].startswith('8g') == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "print(type(parsed_dataML8g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfML8g = parsed_dataML8g.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dfML8g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_1', '_2', '_3', '_4', '_5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfML8g.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|features|    label|\n",
      "+--------+---------+\n",
      "|   [0.0]|297.67184|\n",
      "|   [3.0]|297.52185|\n",
      "|  [11.0]|297.53186|\n",
      "|   [1.0]|299.29187|\n",
      "|   [0.0]|299.15186|\n",
      "|  [29.0]|298.06186|\n",
      "|  [21.0]|297.39185|\n",
      "|  [77.0]|298.10187|\n",
      "|   [0.0]|297.51184|\n",
      "| [100.0]|297.81186|\n",
      "|   [3.0]|297.75186|\n",
      "|  [65.0]|297.29187|\n",
      "|  [22.0]|297.03186|\n",
      "|  [21.0]|297.28186|\n",
      "|   [0.0]|297.20184|\n",
      "|   [5.0]|298.57187|\n",
      "|   [0.0]|297.14185|\n",
      "|  [11.0]|297.25186|\n",
      "|  [24.0]|296.96185|\n",
      "|  [28.0]|297.03186|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+---------+\n",
      "|features|    label|\n",
      "+--------+---------+\n",
      "|   [3.0]|297.67184|\n",
      "|   [3.0]|297.52185|\n",
      "|   [2.0]|297.53186|\n",
      "|  [26.0]|299.29187|\n",
      "|  [25.0]|299.15186|\n",
      "|  [14.0]|298.06186|\n",
      "|   [3.0]|297.39185|\n",
      "|  [10.0]|298.10187|\n",
      "|   [2.0]|297.51184|\n",
      "|   [5.0]|297.81186|\n",
      "|   [5.0]|297.75186|\n",
      "|   [3.0]|297.29187|\n",
      "|   [3.0]|297.03186|\n",
      "|   [2.0]|297.28186|\n",
      "|   [3.0]|297.20184|\n",
      "|  [24.0]|298.57187|\n",
      "|   [3.0]|297.14185|\n",
      "|   [3.0]|297.25186|\n",
      "|   [3.0]|296.96185|\n",
      "|   [3.0]|297.03186|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+---------+\n",
      "|   features|    label|\n",
      "+-----------+---------+\n",
      "| [7.737025]|297.67184|\n",
      "|[6.5370245]|297.52185|\n",
      "| [8.237024]|297.53186|\n",
      "| [7.637025]|299.29187|\n",
      "|[7.4370246]|299.15186|\n",
      "| [7.137025]|298.06186|\n",
      "|[7.5370245]|297.39185|\n",
      "|[7.0370245]|298.10187|\n",
      "| [8.337025]|297.51184|\n",
      "| [7.137025]|297.81186|\n",
      "|[7.5370245]|297.75186|\n",
      "|[7.0370245]|297.29187|\n",
      "| [8.137025]|297.03186|\n",
      "|[7.9370246]|297.28186|\n",
      "| [7.137025]|297.20184|\n",
      "| [7.237025]|298.57187|\n",
      "|[7.9370246]|297.14185|\n",
      "| [8.137025]|297.25186|\n",
      "|[7.3370247]|296.96185|\n",
      "|[6.5370245]|297.03186|\n",
      "+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1: 8g\n",
    "'''\n",
    "original result:\n",
    "#-----------------\n",
    "geohash: 8g\n",
    "humidity: \n",
    "[[ 1.         -0.07573358]\n",
    " [-0.07573358  1.        ]]\n",
    "wind_speed: \n",
    "[[ 1.        -0.0757577]\n",
    " [-0.0757577  1.       ]]\n",
    "could_cover: \n",
    "[[ 1.         -0.38374192]\n",
    " [-0.38374192  1.        ]]\n",
    "-----------------\n",
    "'''\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "def prepare_data(dframe, predictors, target):\n",
    "    assembler = VectorAssembler(inputCols=predictors, outputCol=\"features\")\n",
    "    output = assembler.transform(dframe)\n",
    "    return output.select(\"features\", target).withColumnRenamed(target, \"label\")\n",
    "\n",
    "# Choose our dependent and independent variables:\n",
    "#1: cloud\n",
    "prepped8gCloud = prepare_data(dfML8g,\n",
    "    ['_5'],\n",
    "    '_2')\n",
    "\n",
    "prepped8gCloud.show()\n",
    "(trainingData8gCloud, testData8gCloud) = prepped8gCloud.randomSplit([0.9, 0.1])\n",
    "\n",
    "#1: humidity\n",
    "prepped8gHumidity = prepare_data(dfML8g,\n",
    "    ['_3'],\n",
    "    '_2')\n",
    "\n",
    "prepped8gHumidity.show()\n",
    "(trainingData8gHumidity, testData8gHumidity) = prepped8gHumidity.randomSplit([0.9, 0.1])\n",
    "\n",
    "#1: wind_speed\n",
    "prepped8gWind = prepare_data(dfML8g,\n",
    "    ['_4'],\n",
    "    '_2')\n",
    "\n",
    "prepped8gWind.show()\n",
    "(trainingData8gWind, testData8Wind) = prepped8gWind.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud: Root Mean Squared Error (RMSE) on test data = 1.06573\n",
      "Humidity: Root Mean Squared Error (RMSE) on test data = 1.06734\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#We use same parameter for all predictors\n",
    "rf8g = RandomForestRegressor(numTrees=100, maxDepth=5, maxBins=32)\n",
    "\n",
    "#1: cloud\n",
    "model = rf8g.fit(trainingData8gCloud)\n",
    "predictions = model.transform(testData8gCloud)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Cloud: Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "#2: humidity\n",
    "model = rf8g.fit(trainingData8gHumidity)\n",
    "predictions = model.transform(testData8gHumidity)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Humidity: Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "\n",
    "#1: wind_speed\n",
    "model = rf8g.fit(trainingData8gWind)\n",
    "predictions = model.transform(testData8Wind)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Wind: Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
