{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly Detector: Reusing the multi-threaded dataset emitter from the previous question, design an algorithm that uses streaming frequency estimation to build a representation of feature distributions. Using this information, you will be able to flag incoming records as either normal or anomalous, but also update your anomaly detector over time so it adapts to gradual changes in the input streams.\n",
    "\n",
    "Doing this across all spatial locations in the dataset clearly will not work; data points from Florida would be considered anomalous if they were found in a stream describing Montana. Come up with a strategy to avoid this problem.\n",
    "Track each feature in the dataset and produce an anomaly score: the more features in a given observation that are considered anomalous, the higher the score. One approach could be 0% = no anomalies, 100% = all features were flagged as anomalous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import geohash\n",
    "gh_features_dict = {} # wxyz -> (count, pmw, ps, pt, hum, sd, ts, tt, prec, vs, vis) \n",
    "\n",
    "ano_dict = {}\n",
    "\n",
    "def update_mean(newValue, count, existingAggregate):   \n",
    "    count = count + 1\n",
    "    (mean, M2) = existingAggregate\n",
    "    delta = newValue - mean\n",
    "    mean += delta / count\n",
    "    delta2 = newValue - mean\n",
    "    M2 += delta * delta2\n",
    "    return (mean, M2)\n",
    "\n",
    "def is_anomalous(value, mean, sampleVarience):\n",
    "    standard_deviation = math.sqrt(sampleVarience)\n",
    "    upper_bound = mean + (3 * standard_deviation)\n",
    "    lower_bound = mean - (3 * standard_deviation)\n",
    "    if(value > upper_bound or value < lower_bound):\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "    \n",
    "    \n",
    "def parseLine(line):\n",
    "    if line.startswith('1_'):\n",
    "        return \n",
    "    variables = line.split(\"\\t\")\n",
    "    \n",
    "    milliseconds = int(variables[0])\n",
    "    dt = datetime.datetime.fromtimestamp(milliseconds/1000.0)\n",
    "    lat = float(variables[1])\n",
    "    lon = float(variables[2])\n",
    "    pressure_maximum_wind = float(variables[5])\n",
    "    pressure_surface = float(variables[6])\n",
    "    pressure_tropopause = float(variables[7])\n",
    "    humidity = float(variables[8])\n",
    "    snow_depth_surface = float(variables[9])\n",
    "    temperature_surface = float(variables[10])\n",
    "    temperature_tropopause = float(variables[11])\n",
    "    precipitation = float(variables[13])\n",
    "    vegetation_surface = float(variables[14])                          \n",
    "    visibility = float(variables[15])\n",
    "    \n",
    "    newValues = [1, pressure_maximum_wind, pressure_surface, pressure_tropopause, humidity, \\\n",
    "                snow_depth_surface, temperature_surface, temperature_tropopause, precipitation, \\\n",
    "                vegetation_surface, visibility]\n",
    "    gh = geohash.encode(lat, lon)[0:6]\n",
    "    \n",
    "    anomalous_score = 0\n",
    "    if gh in gh_features_dict:\n",
    "        features = gh_features_dict[gh]\n",
    "        cnt = features[0]\n",
    "        if(cnt > 3):\n",
    "            for i in range(1, 10):\n",
    "                (mean, M2) = features[i]\n",
    "                sampleVariance =  M2 / (cnt - 1)\n",
    "                anomalous_score += 10 if is_anomalous(newValues[i], mean, sampleVariance) else 0\n",
    "    else : \n",
    "        features = [0, (0,0), (0,0), (0,0), (0,0), (0,0), (0,0), (0,0), (0,0), (0,0), (0,0)]\n",
    "    \n",
    "    cnt = features[0]\n",
    "    features[0] = cnt + 1\n",
    "    for i in range(1, 10) : \n",
    "        features[i]  = update_mean(newValues[i], cnt, features[i])\n",
    "    gh_features_dict[gh] = features\n",
    "    \n",
    "    if anomalous_score > 30:\n",
    "        print(line)\n",
    "    \n",
    "                \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450299600000\t51.12617467345033\t-91.65211896209196\t25.5\tnull\t33323.61\t95117.0\t30119.004\t85.0\t0.24399999\t264.51862\t221.40625\tnull\t2.125\t1.0\t1621.8237\t0.0475\tnull\n",
      "\n",
      "1450299600000\t47.06974253786414\t-96.99679013665887\t67.5\tnull\t13323.611\t96636.0\t34719.004\t88.0\t0.12719999\t268.76862\t226.53125\tnull\t0.125\t1.0\t6021.8237\t0.12\tnull\n",
      "\n",
      "1450299600000\t37.796356518329965\t-103.72296470055775\t66.25\tnull\t17923.611\t85352.0\t29319.004\t80.0\t0.0448\t273.01862\t223.03125\tnull\t0.0\t7.0\t24221.824\t0.083749995\tnull\n",
      "\n",
      "1450299600000\t45.08247255624026\t-113.43216886254368\t43.0\tnull\t29523.611\t77470.0\t38519.004\t88.0\t0.28\t268.39362\t227.90625\tnull\t2.375\t1.0\t3221.8237\t0.06625\tnull\n",
      "\n",
      "1450299600000\t43.7406732146168\t-102.95182169302863\t70.0\tnull\t29723.611\t90353.0\t27519.004\t89.0\t0.14999999\t271.39362\t220.03125\tnull\t0.0\t7.0\t24221.824\t0.0275\tnull\n",
      "\n",
      "1450299600000\t42.34764178618597\t-95.91195493224608\t23.5\tnull\t18523.611\t95996.0\t31519.004\t74.0\t0.0052\t272.39362\t223.65625\tnull\t0.0\t6.0\t24221.824\t0.083749995\tnull\n",
      "\n",
      "1450299600000\t48.10357178892677\t-103.6298806537851\t71.0\tnull\t49123.61\t93476.0\t30719.004\t86.0\t0.0928\t269.89362\t222.15625\tnull\t0.0\t1.0\t20421.824\t0.06625\tnull\n",
      "\n",
      "1427662800000\t56.23746255828788\t-90.93470504965802\t52.75\tnull\t16326.767\t98962.0\t35828.918\t86.0\t0.42839998\t265.05023\t225.73079\tnull\t0.125\t1.0\t17019.129\t0.06625\tnull\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('sample.txt', 'r')\n",
    "for line in f.readlines() :\n",
    "    parseLine(line)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
